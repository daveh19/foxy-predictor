{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: change the path specifications before using....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.debugger import Tracer\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# this is where the data comes from\n",
    "datapath = \"/home/newuser/Dokumente/programming_project/Predictor/data\"\n",
    "\n",
    "# labels needed to generate standardized output\n",
    "labels = [\"Datum\", \"CDU\", \"SPD\", \"Gruene\", \"FDP\", \"Linke\", \"AfD\", \"Sonstige\",\"Befragte\", \"Institute\"]\n",
    "institutes = [\"forsa\", \"emnid\", \"allensbach\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we read in the latest predictions from \"forsa\", \"emnid\" and \"allensbach\" and write them \n",
    "# to a .csv - file (called \"helper_simple_regression.csv\"). This procedure might not be optimal \n",
    "# ... but it works. \n",
    "\n",
    "test_latest = open(\"helper_simple_regression.csv\", \"w\")\n",
    "\n",
    "for i, lab in enumerate(labels):\n",
    "    test_latest.write(lab)\n",
    "    if i < len(labels): \n",
    "        test_latest.write(',')\n",
    "test_latest.write('\\n')\n",
    "\n",
    "for k, inst in enumerate(institutes): \n",
    "    name = inst + \".csv\"\n",
    "    file = os.path.join(datapath, name)\n",
    "    datafile = pd.read_csv(file, encoding=\"ISO-8859-1\")\n",
    "    for i in range(len(labels)-1):\n",
    "        test_latest.write(str(datafile[labels[i]][0]))\n",
    "        test_latest.write(',')\n",
    "    test_latest.write(inst)\n",
    "    test_latest.write('\\n')\n",
    "        \n",
    "test_latest.close()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we open the above generated \"helper_simple_regression.csv\" as a pandas dataframe. \n",
    "# The csv is not used further. \n",
    "\n",
    "latest = pd.read_csv(\"/home/newuser/Dokumente/programming_project/Predictor/models/helper_simple_regression.csv\",  encoding=\"ISO-8859-1\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_output_csv(modelname):\n",
    "    \"\"\"This function takes the name of a model as argument and generates a .csv-file with \n",
    "    labelled columns where all further predictions from that model will be stored. The \n",
    "    structure of the csv is described in \"model_output_structure.txt\" \"\"\"\n",
    "   \n",
    "    filename = modelname + \".csv\"\n",
    "    \n",
    "    labels = [\"modelname\", \"prediction_date\", \"CDU\", \"SPD\", \"Gruene\", \"FDP\", \"Linke\", \"AfD\", \"Sonstige\", \n",
    "              \"forsa\", \"emnid\", \"allensbach\", \"startdate\", \"enddate\"]\n",
    "    \n",
    "    out = open(filename, \"w\")\n",
    "    \n",
    "    for i, label in enumerate(labels): \n",
    "        if i < len(labels):\n",
    "            out.write(label + \" , \")\n",
    "    out.write(\"\\n\")\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_to_output_csv(modelname, date, data, forsa, emnid, allensbach, start, end): \n",
    "    \"\"\" This function is called after each prediction and adds a line to the .csv-file \n",
    "    corresponding to the model that was used for prediction. The files containing prediction \n",
    "    data are named \"modelname.csv\" and their structure  is described in the \n",
    "    \"model_output_structure.txt\" file. \"\"\"\n",
    "    \n",
    "    filename = modelname + \".csv\"\n",
    "    \n",
    "    if os.path.isfile(filename): #check if the current model already has a file for predictions\n",
    "        out = open(filename,'a')\n",
    "    else: # if no prediction file exists one is generated using the function \"generate_output_csv\"\n",
    "        generate_output_csv(modelname) \n",
    "        out  = open(filename,'a')\n",
    "        \n",
    "    # here all relevant information aout the new prediction is appended\n",
    "    out.write(modelname + \",\")   \n",
    "    out.write(date + \",\")\n",
    "    for i in range(len(data)): \n",
    "        out.write(str(data[i][0]) + \",\")\n",
    "    out.write(str(forsa) + \",\")\n",
    "    out.write(str(emnid) + \",\")\n",
    "    out.write(str(allensbach) + \",\")\n",
    "    out.write(str(start) + \",\")\n",
    "    out.write(str(end) + \",\")\n",
    "    out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_model(dataframe):\n",
    "    \"\"\" This model takes a a dataframe containing the latest predictions from different\n",
    "    institutes. The model calculates a weighted average of these prediction the weights\n",
    "    being the number of participants in the survey. \"\"\"\n",
    "        \n",
    "    prediction = np.zeros((7,1))\n",
    "    labs =  dataframe.columns\n",
    "    party_lables = labs[1: 7]\n",
    "    weights = dataframe[\"Befragte\"]\n",
    "    total = sum(weights)\n",
    "    for k, pl in enumerate(party_lables): \n",
    "        prediction[k] = sum(dataframe[pl] * weights) / total\n",
    "    \n",
    "    modelname = sys._getframe().f_code.co_name\n",
    "    date = time.strftime(\"%x\")\n",
    "    start = min(dataframe['Datum'])\n",
    "    end = max(dataframe['Datum'])\n",
    "    \n",
    "    add_to_output_csv(modelname, date, prediction, 1, 1, 1, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(dataframe, depth, parties):    \n",
    "    \"\"\" This model performs linear regression.\n",
    "    \n",
    "    Note: currently this only makes sense to use for data from one institute, \n",
    "    else the dates of surveys might not be equally spaced. \n",
    "    \n",
    "    Input:\n",
    "        datafile ..... pandas file containing equally spaced survey data\n",
    "        depth ........ number of data point to be taken into account\n",
    "        parties....... list of strings containing the parties to be taken into account\n",
    "        \n",
    "    Output: \n",
    "        predictions... np.array with predictions for each party\n",
    "    \"\"\"\n",
    "    \n",
    "    # create np.array conatining the predictions for selected parties \n",
    "    # shape = predictions * parties\n",
    "    data_for_regression = dataframe.as_matrix(parties)\n",
    "    data_for_regression = data_for_regression[:depth, :] #choose only the latest datapoints\n",
    "    \n",
    "    biases = np.zeros(len(parties))\n",
    "    coeffs = np.zeros(len(parties))\n",
    "    \n",
    "    prediction = np.zeros((len(parties),1))\n",
    "    \n",
    "    for p in range(len(parties)):\n",
    "        y = data_for_regression[:,p]\n",
    "        y = y[~np.isnan(y)]\n",
    "        \n",
    "        x = np.arange(0, len(y), 1)\n",
    "    \n",
    "        lm = LinearRegression()\n",
    "        lm.fit(x.reshape(-1,1), y)\n",
    "\n",
    "        biases[p] = lm.intercept_\n",
    "        coeffs[p] = lm.coef_ \n",
    "        \n",
    "        prediction[p] = len(y)*coeffs[p] + biases[p]\n",
    "        \n",
    "        modelname = sys._getframe().f_code.co_name + \" depth =\" + str(depth)\n",
    "        date = time.strftime(\"%x\")\n",
    "        start = min(dataframe['Datum'])\n",
    "        end = max(dataframe['Datum'])\n",
    "    \n",
    "    add_to_output_csv(modelname, date, prediction, 1, 0, 0, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data_forsa = pd.read_csv(\"/home/newuser/Dokumente/programming_project/Predictor/data/forsa.csv\")\n",
    "p = [\"CDU\", \"SPD\", \"Gruene\", \"FDP\", \"Linke\", \"AfD\", \"Sonstige\"]\n",
    "depth = 20\n",
    "linear_regression(data_forsa, depth, p )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
