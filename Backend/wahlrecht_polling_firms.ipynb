{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T09:14:37.178696Z",
     "start_time": "2017-05-23T09:14:37.164026"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis script extracts tables from the website 'http://www.wahlrecht.de/umfragen/' \\nfor each polling firm individually.\\n\\nCall the function get_tables() will return a dictionary containing the firm names \\nas keywords and corresponding Pandas dataframe as values.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script extracts tables from the website 'http://www.wahlrecht.de/umfragen/' \n",
    "for each polling firm individually.\n",
    "\n",
    "Call the function get_tables() will return a dictionary containing the firm names \n",
    "as keywords and corresponding Pandas dataframe as values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T09:14:55.354334Z",
     "start_time": "2017-05-23T09:14:55.337338"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "wahlrecht = 'http://www.wahlrecht.de/umfragen/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_table_from_polling_firm(url):\n",
    "    \"\"\"\n",
    "    extracts tables from the website 'http://www.wahlrecht.de/umfragen/'\n",
    "    for each polling firm, and stores the tables into Pandas dataframes.\n",
    "    \n",
    "    url:    str, the full url of the website, \n",
    "            e.g. 'http://www.wahlrecht.de/umfragen/emnid.htm'\n",
    "    Return: Pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    head = soup.find('thead')\n",
    "    body = soup.find('tbody')\n",
    "\n",
    "    table = []\n",
    "    rows = body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        table.append([ele for ele in cols if ele]) \n",
    "\n",
    "    header = []\n",
    "    cols = head.find_all('th')\n",
    "    for col in cols:\n",
    "        if col.get_text() != '\\xa0':\n",
    "            header.append(col.get_text())\n",
    "    if header.count('Datum') == 0:\n",
    "        header.insert(0, 'Datum')\n",
    "\n",
    "    df = pd.DataFrame(table, columns=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(table):\n",
    "    \"\"\"\n",
    "    converts the table that consists of strings into a table containing the correct type\n",
    "    df: pandas dataframe \n",
    "    return: pandas dataframe \n",
    "    \"\"\"\n",
    "    # drop the column Zeitraum\n",
    "    table = table.drop('Zeitraum', axis=1)\n",
    "    # drop the rows containing the true results of the elections\n",
    "    Idx = np.where(table.Befragte=='Bundestagswahl')[0]\n",
    "    Idx = np.append(Idx, np.where(table['CDU/CSU'].str.contains('Umfrage'))[0])\n",
    "    table = table.drop(Idx)\n",
    "    table.index = np.arange(table.shape[0])\n",
    "    # replace the strings %,-\n",
    "    table = table.replace('%', '', regex=True)\n",
    "    table = table.replace(',', '.', regex=True)\n",
    "    table = table.replace('[–?]', '', regex=True)\n",
    "    # fix the column Befragte !!!!!!!!!!!!!!\n",
    "    table.Befragte = table.Befragte.replace('[T • ?≈O • .]', '', regex=True)\n",
    "    # replace all empty entries with NaN\n",
    "    table = table.replace('', 'NaN', regex=True)\n",
    "\n",
    "    # if the colomn Sonstige contains entries with more than one number\n",
    "    try: \n",
    "        table.Sonstige = table.Sonstige.astype(float)\n",
    "    except ValueError:\n",
    "        for i, n in enumerate(table.Sonstige):\n",
    "            if len(n) > 2:\n",
    "                digits = np.array([digit for digit in np.arange(10).astype(str) if digit in n])\n",
    "                table.Sonstige[i] = digits.astype(int).sum()\n",
    "                table.Sonstige = table.Sonstige.astype(float)\n",
    "\n",
    "    # convert all numbers to float\n",
    "    table[table.keys()[1:]] = table[table.keys()[1:]].astype(float)\n",
    "    # convert the date to type date\n",
    "    table.Datum = pd.to_datetime(table.Datum, format='%d.%m.%Y').dt.date\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_tables():\n",
    "    \"\"\"\n",
    "    goes through the website 'http://www.wahlrecht.de/umfragen/'\n",
    "    and extracts the table for all polling firms individually, \n",
    "    by using get_table_from_polling_firm(arg).\n",
    "    \n",
    "    Return: a dictionary containing the names of polling firms as keywords and the \n",
    "            pd dataframes as values.\n",
    "    \"\"\"\n",
    "    \n",
    "    tables = {}\n",
    "    \n",
    "    page = urllib.request.urlopen(wahlrecht)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    firms_url = []\n",
    "    rows = soup.find_all(class_='in')\n",
    "    for row in rows:\n",
    "        #print(row)\n",
    "        link = row.find('a')\n",
    "        #print(link.get('href'))\n",
    "        firms_url.append(link.get('href'))\n",
    "\n",
    "    for url in firms_url:\n",
    "        key = url.split('.')[0]\n",
    "        #print(key)\n",
    "        df = get_table_from_polling_firm(wahlrecht+url)\n",
    "        #df.to_csv('data/' + url.split('.')[0] + '.csv')\n",
    "        df = preprocess(df)\n",
    "        tables[key] = df\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tables = get_tables()\n",
    "table = tables.get('forsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
