{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-23T09:13:44.877995Z",
     "start_time": "2017-05-23T09:13:44.867162Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_tables():\n",
    "    \"\"\"\n",
    "    Goes through the website 'http://www.wahlrecht.de/umfragen/laender.htm'\n",
    "    and extracts the table for states individually, \n",
    "    \n",
    "    Return: a dictionary containing the id names of the states as keywords and the \n",
    "            pd dataframes as values.\n",
    "    \"\"\"\n",
    "    tables = {} # {'state': df}\n",
    "\n",
    "    page = urllib.request.urlopen('http://www.wahlrecht.de/umfragen/laender.htm')\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    # Find the subtables\n",
    "    states = soup.find_all('th', colspan='10', id=True)\n",
    "    rows = soup.find_all('tr')\n",
    "    header = [col.get_text() for col in soup.find_all('th', class_=True, limit=9)]\n",
    "    #header = []\n",
    "    \n",
    "    # Initialize with empty/unimportant values\n",
    "    table = [] # df\n",
    "    new_table = pd.DataFrame()\n",
    "    name = \"ignore\"\n",
    "    for row in rows:\n",
    "        # Start point of a new state\n",
    "        if row.find('th', colspan='10', id=True) != None:\n",
    "            table = []\n",
    "            #new_table = pd.DataFrame()\n",
    "            name = row.contents[1].get('id')\n",
    "            #header = row.find_all_next('th', class_=True, limit=9)\n",
    "\n",
    "        # Read the data of the subtable\n",
    "        cols = row.find_all('td', rowspan=False)\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        #table.append([ele for ele in cols if ele])\n",
    "        table.append([ele if ele else None for ele in cols])\n",
    "        \n",
    "        # End point for each state\n",
    "        if row.find('th', colspan='10', class_=\"trenner\") != None: \n",
    "            # Don't use the information outside the states.\n",
    "            if name != \"ignore\" and name != 'hb':\n",
    "                tables[name] = pd.DataFrame(table, columns=header)\n",
    "            # Handle differentely the information from hb = Bremen, which is empty.\n",
    "            elif name == 'hb':\n",
    "                tables[name] = pd.DataFrame(table, columns=header[:8])\n",
    "    \n",
    "    # Add last table, that doesn't have trenner at the end\n",
    "    tables[name] = pd.DataFrame(table, columns=header)\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = get_states_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying other versions to parse, this uses object oriented programming.\n",
    "# It's not yet suitable for our case, because tables are very messy.\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return [(table['id'],self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
